{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Applying ML models to our new supervised quora dataset\n",
    "Previously we transformed the quora dataset into supervised dataset by preprocessing the data , now we are going to perform some train and testing on this new dataset so as to understand the accuracy of the new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#importing the necessary libraries needed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>text_low_case</th>\n",
       "      <th>text_punct</th>\n",
       "      <th>text_stop</th>\n",
       "      <th>text_token</th>\n",
       "      <th>text_lemma</th>\n",
       "      <th>Topic number</th>\n",
       "      <th>Topic desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What step step guide invest share market india</td>\n",
       "      <td>['what', 'step', 'step', 'guide', 'invest', 's...</td>\n",
       "      <td>What step step guide invest share market india</td>\n",
       "      <td>5</td>\n",
       "      <td>economy,nation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>what is the story of kohinoor (koh-i-noor) dia...</td>\n",
       "      <td>What is the story of Kohinoor KohiNoor Diamond</td>\n",
       "      <td>What story Kohinoor KohiNoor Diamond</td>\n",
       "      <td>['what', 'story', 'kohinoor', 'kohinoor', 'dia...</td>\n",
       "      <td>What story Kohinoor KohiNoor Diamond</td>\n",
       "      <td>5</td>\n",
       "      <td>economy,nation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>how can i increase the speed of my internet co...</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How I increase speed internet connection using...</td>\n",
       "      <td>['how', 'i', 'increase', 'speed', 'internet', ...</td>\n",
       "      <td>How I increase speed internet connection use VPN</td>\n",
       "      <td>9</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>why am i mentally very lonely? how can i solve...</td>\n",
       "      <td>Why am I mentally very lonely How can I solve it</td>\n",
       "      <td>Why I mentally lonely How I solve</td>\n",
       "      <td>['why', 'i', 'mentally', 'lonely', 'how', 'i',...</td>\n",
       "      <td>Why I mentally lonely How I solve</td>\n",
       "      <td>7</td>\n",
       "      <td>Relationships</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which one dissolve in water quikly sugar salt ...</td>\n",
       "      <td>Which one dissolve water quikly sugar salt met...</td>\n",
       "      <td>['which', 'one', 'dissolve', 'water', 'quikly'...</td>\n",
       "      <td>Which one dissolve water quikly sugar salt met...</td>\n",
       "      <td>4</td>\n",
       "      <td>Fitness, health</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What is the step by step guide to invest in sh...   \n",
       "1  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2  How can I increase the speed of my internet co...   \n",
       "3  Why am I mentally very lonely? How can I solve...   \n",
       "4  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                       text_low_case  \\\n",
       "0  what is the step by step guide to invest in sh...   \n",
       "1  what is the story of kohinoor (koh-i-noor) dia...   \n",
       "2  how can i increase the speed of my internet co...   \n",
       "3  why am i mentally very lonely? how can i solve...   \n",
       "4  which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                          text_punct  \\\n",
       "0  What is the step by step guide to invest in sh...   \n",
       "1     What is the story of Kohinoor KohiNoor Diamond   \n",
       "2  How can I increase the speed of my internet co...   \n",
       "3   Why am I mentally very lonely How can I solve it   \n",
       "4  Which one dissolve in water quikly sugar salt ...   \n",
       "\n",
       "                                           text_stop  \\\n",
       "0     What step step guide invest share market india   \n",
       "1               What story Kohinoor KohiNoor Diamond   \n",
       "2  How I increase speed internet connection using...   \n",
       "3                  Why I mentally lonely How I solve   \n",
       "4  Which one dissolve water quikly sugar salt met...   \n",
       "\n",
       "                                          text_token  \\\n",
       "0  ['what', 'step', 'step', 'guide', 'invest', 's...   \n",
       "1  ['what', 'story', 'kohinoor', 'kohinoor', 'dia...   \n",
       "2  ['how', 'i', 'increase', 'speed', 'internet', ...   \n",
       "3  ['why', 'i', 'mentally', 'lonely', 'how', 'i',...   \n",
       "4  ['which', 'one', 'dissolve', 'water', 'quikly'...   \n",
       "\n",
       "                                          text_lemma  Topic number  \\\n",
       "0     What step step guide invest share market india             5   \n",
       "1               What story Kohinoor KohiNoor Diamond             5   \n",
       "2   How I increase speed internet connection use VPN             9   \n",
       "3                  Why I mentally lonely How I solve             7   \n",
       "4  Which one dissolve water quikly sugar salt met...             4   \n",
       "\n",
       "        Topic desc  \n",
       "0   economy,nation  \n",
       "1   economy,nation  \n",
       "2       technology  \n",
       "3    Relationships  \n",
       "4  Fitness, health  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading and loading the dataset\n",
    "df1= pd.read_csv('C:/AI2/quora_supervised_LDA.csv')\n",
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#importing train_test_split ffrom scikit learn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#first we will split the data into labels and features so here we are taking \n",
    "#the column 'text_token 'as the feature  and 'topic desc ' as label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "now we will see the count of words in the token_text and Topic desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['how', 'i', 'improve', 'pronunciation', 'english']                                                                                                                        58\n",
       "['what', 'meaning', 'life']                                                                                                                                                39\n",
       "['how', 'i', 'speak', 'english', 'fluently']                                                                                                                               37\n",
       "['what', 'new', 'years', 'resolutions', '2017']                                                                                                                            36\n",
       "['what', 'purpose', 'life']                                                                                                                                                34\n",
       "                                                                                                                                                                           ..\n",
       "['is', 'profitable', 'attach', 'car', 'cab', 'cos', 'like', 'olataxi', 'suremeru', 'cabs', 'what', 'net', 'returns', 'calculating', 'practical', 'incomes', 'expenses']     1\n",
       "['how', 'i', 'rephrase', 'did', 'get', 'chance', 'look']                                                                                                                    1\n",
       "['how', 'i', 'verify', 'instagram', 'account', 'email']                                                                                                                     1\n",
       "['which', 'best', 'whey', 'concentrate', 'protein', 'available', 'market']                                                                                                  1\n",
       "['what', 'rich', 'people', 'think']                                                                                                                                         1\n",
       "Name: text_token, Length: 158804, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[\"text_token\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "entertainment           25706\n",
       "technology              23587\n",
       "Relationships           21960\n",
       "education               21034\n",
       "Fitness, health         20375\n",
       "life,feelings           18826\n",
       "Government,judiciary    18645\n",
       "human life              17055\n",
       "Humanities,feelings     16645\n",
       "economy,nation          16167\n",
       "Name: Topic desc, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[\"Topic desc\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X = df1[\"text_token\"]\n",
    "y = df1[\"Topic desc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ['what', 'step', 'step', 'guide', 'invest', 's...\n",
       "1    ['what', 'story', 'kohinoor', 'kohinoor', 'dia...\n",
       "2    ['how', 'i', 'increase', 'speed', 'internet', ...\n",
       "3    ['why', 'i', 'mentally', 'lonely', 'how', 'i',...\n",
       "4    ['which', 'one', 'dissolve', 'water', 'quikly'...\n",
       "Name: text_token, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     economy,nation\n",
       "1     economy,nation\n",
       "2         technology\n",
       "3      Relationships\n",
       "4    Fitness, health\n",
       "Name: Topic desc, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train_counts = count_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<140000x49077 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 888725 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140000,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140000, 49077)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the tfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# Creating an instance of TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "# Perform a tf-idf fit transform on the X_train_counts\n",
    "# sparse matrix. Put the result into X_train_tfidf\n",
    "X_train_transform = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "# Shape is the same as original count vectorizer\n",
    "# although it now contains word term frequencies multiplied by the\n",
    "# inverse document frequency\n",
    "X_train_transform.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140000, 49077)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Complete the vectorizing and fit transform on the original X_train\n",
    "# dataset\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "# Examine shape of the dataset\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Performing Linear SVC on the train test dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49673     ['i', '23yrs', 'ca', 'final', 'student', 'clea...\n",
       "171551    ['demonetization', '500', '1000', 'notes', 'cr...\n",
       "5506      ['what', 'best', 'way', 'learn', 'everything',...\n",
       "38370                          ['what', 'system', 'theory']\n",
       "36930     ['has', 'jimmy', 'swaggart', 'ever', 'grammy',...\n",
       "Name: text_token, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Contents of X_test\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating an instance of the LinearSVC classifier\n",
    "classifier = LinearSVC()\n",
    "\n",
    "# Target vector relative to X\n",
    "classifier.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Transform original test message data to a vector\n",
    "# No need to fit and transform it\n",
    "X_test_transform = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Predict message type from Linear SVC classifier\n",
    "predictions = classifier.predict(X_test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predictions contains the predicted label data from inputted message test data\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5266   95   95  126   55   80  111  133   99   73]\n",
      " [  95 4716   85  101   83   76   85   91  118   91]\n",
      " [ 109  106 4015  140   75  109  124  119  103  143]\n",
      " [ 115  101  113 5565   77  102  129  117  144  150]\n",
      " [  69   78   72   82 4142   91   92   80   59   88]\n",
      " [  76   65   96  144   59 5378  149  110   78  141]\n",
      " [ 106   76   93   75   65  122 6904   96  115  149]\n",
      " [ 143   99   98  140   71  158  127 3941  142  110]\n",
      " [ 128  116   68  189   80   77  118  127 4557   98]\n",
      " [  55   63   82  109   60  141  132   84   79 6328]]\n"
     ]
    }
   ],
   "source": [
    "# Showing a confusion matrix of results\n",
    "from sklearn import metrics\n",
    "print(metrics.confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      precision    recall  f1-score   support\n",
      "\n",
      "     Fitness, health       0.85      0.86      0.86      6133\n",
      "Government,judiciary       0.86      0.85      0.85      5541\n",
      " Humanities,feelings       0.83      0.80      0.81      5043\n",
      "       Relationships       0.83      0.84      0.84      6613\n",
      "      economy,nation       0.87      0.85      0.86      4853\n",
      "           education       0.85      0.85      0.85      6296\n",
      "       entertainment       0.87      0.89      0.88      7801\n",
      "          human life       0.80      0.78      0.79      5029\n",
      "       life,feelings       0.83      0.82      0.82      5558\n",
      "          technology       0.86      0.89      0.87      7133\n",
      "\n",
      "            accuracy                           0.85     60000\n",
      "           macro avg       0.85      0.84      0.84     60000\n",
      "        weighted avg       0.85      0.85      0.85     60000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print a classification report\n",
    "print(metrics.classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf_vect',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('LinearSVC_classifier',\n",
       "                 LinearSVC(C=1.0, class_weight=None, dual=True,\n",
       "                           fit_intercept=True, intercept_scaling=1,\n",
       "                           loss='squared_hinge', max_iter=1000,\n",
       "                           multi_class='ovr', penalty='l2', random_state=None,\n",
       "                           tol=0.0001, verbose=0))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "text_classifier = Pipeline([('tfidf_vect', TfidfVectorizer()),\n",
    "                     ('LinearSVC_classifier', LinearSVC()),\n",
    "])\n",
    "\n",
    "# Feed the training data through the pipeline\n",
    "text_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "predictions = text_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5266   95   95  126   55   80  111  133   99   73]\n",
      " [  95 4716   85  101   83   76   85   91  118   91]\n",
      " [ 109  106 4015  140   75  109  124  119  103  143]\n",
      " [ 115  101  113 5565   77  102  129  117  144  150]\n",
      " [  69   78   72   82 4142   91   92   80   59   88]\n",
      " [  76   65   96  144   59 5378  149  110   78  141]\n",
      " [ 106   76   93   75   65  122 6904   96  115  149]\n",
      " [ 143   99   98  140   71  158  127 3941  142  110]\n",
      " [ 128  116   68  189   80   77  118  127 4557   98]\n",
      " [  55   63   82  109   60  141  132   84   79 6328]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_test,predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      precision    recall  f1-score   support\n",
      "\n",
      "     Fitness, health       0.85      0.86      0.86      6133\n",
      "Government,judiciary       0.86      0.85      0.85      5541\n",
      " Humanities,feelings       0.83      0.80      0.81      5043\n",
      "       Relationships       0.83      0.84      0.84      6613\n",
      "      economy,nation       0.87      0.85      0.86      4853\n",
      "           education       0.85      0.85      0.85      6296\n",
      "       entertainment       0.87      0.89      0.88      7801\n",
      "          human life       0.80      0.78      0.79      5029\n",
      "       life,feelings       0.83      0.82      0.82      5558\n",
      "          technology       0.86      0.89      0.87      7133\n",
      "\n",
      "            accuracy                           0.85     60000\n",
      "           macro avg       0.85      0.84      0.84     60000\n",
      "        weighted avg       0.85      0.85      0.85     60000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print a classification report\n",
    "print(metrics.classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8468666666666667\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "As we can see the Linear SVC model gives the accuracy of 84% and it is the highest accuracy amongst all the models i trained so i have taken 10 random questions from the dataset provided and predicted its group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['economy,nation'], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q1 \n",
    "text_classifier.predict([\"What is the step by step guide to invest in share market in india?\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['technology'], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q2\n",
    "text_classifier.predict([\"How can I increase the speed of my internet connection while using a VPN?\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['life,feelings'], dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q3\n",
    "text_classifier.predict([\"Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me?\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['human life'], dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q4\n",
    "text_classifier.predict([\"What was your first sexual experience like?\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['technology'], dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q5\n",
    "text_classifier.predict([\"What are the questions should not ask on Quora?\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['technology'], dtype=object)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q6\n",
    "text_classifier.predict([\"What is web application?\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['life,feelings'], dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q7\n",
    "text_classifier.predict([\"What Game of Thrones villain would be the most likely to give you mercy?\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Government,judiciary'], dtype=object)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q8\n",
    "text_classifier.predict([\"Why do some people think Obama will try to take their guns away?\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['technology'], dtype=object)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q9\n",
    "text_classifier.predict([\"When can I expect my Cognizant confirmation mail?\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['life,feelings'], dtype=object)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q10\n",
    "text_classifier.predict([\"Nd she is always sad?\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Building NAive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf_vect',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('M_NB ',\n",
       "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "text_classifier = Pipeline([('tfidf_vect', TfidfVectorizer()),\n",
    "                     ('M_NB ', MultinomialNB()),\n",
    "])\n",
    "\n",
    "# Feed the training data through the pipeline\n",
    "text_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "predictions = text_classifier.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4988   81   39  240   49  119  279   83   79  176]\n",
      " [ 196 4349   35  195   66  131  227   60  134  148]\n",
      " [ 222  186 2635  415   60  369  464   99  164  429]\n",
      " [ 152  119   33 5335   48  168  309   46  123  280]\n",
      " [  98  181   38  167 3381  219  338   52   84  295]\n",
      " [ 127   62   26  343   16 4873  245   35  102  467]\n",
      " [ 144   38   20  113   24  164 6924   33   86  255]\n",
      " [ 315  121   52  354   63  426  398 2759  203  338]\n",
      " [ 244  157   39  384   62  127  318   66 3963  198]\n",
      " [  60   74   13  209   36  162  266   31   66 6216]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      precision    recall  f1-score   support\n",
      "\n",
      "     Fitness, health       0.76      0.81      0.79      6133\n",
      "Government,judiciary       0.81      0.78      0.80      5541\n",
      " Humanities,feelings       0.90      0.52      0.66      5043\n",
      "       Relationships       0.69      0.81      0.74      6613\n",
      "      economy,nation       0.89      0.70      0.78      4853\n",
      "           education       0.72      0.77      0.75      6296\n",
      "       entertainment       0.71      0.89      0.79      7801\n",
      "          human life       0.85      0.55      0.67      5029\n",
      "       life,feelings       0.79      0.71      0.75      5558\n",
      "          technology       0.71      0.87      0.78      7133\n",
      "\n",
      "            accuracy                           0.76     60000\n",
      "           macro avg       0.78      0.74      0.75     60000\n",
      "        weighted avg       0.77      0.76      0.75     60000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75705\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf_vect',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_patt...\n",
       "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                        class_weight=None, criterion='gini',\n",
       "                                        max_depth=None, max_features='auto',\n",
       "                                        max_leaf_nodes=None, max_samples=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=100, n_jobs=None,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "text_classifier = Pipeline([('tfidf_vect', TfidfVectorizer()),\n",
    "                     ('Random_FC ', RandomForestClassifier()),\n",
    "])\n",
    "\n",
    "# Feed the training data through the pipeline\n",
    "text_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "predictions = text_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4392  132  271  278  101  132  235  227  199  166]\n",
      " [ 231 3921  200  214  162  126  174  206  190  117]\n",
      " [ 222  164 3348  218  110  198  237  162  156  228]\n",
      " [ 238  152  255 4741  106  184  265  197  237  238]\n",
      " [ 126  157  206  127 3581  132  158  114  102  150]\n",
      " [ 158   86  178  263  105 4582  302  200  135  287]\n",
      " [ 183   95  200  149  108  149 6399  139  168  211]\n",
      " [ 283  179  272  304  142  251  239 2926  233  200]\n",
      " [ 265  174  262  308  120  116  252  222 3711  128]\n",
      " [ 126   88  178  217  102  165  283  137  108 5729]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      precision    recall  f1-score   support\n",
      "\n",
      "     Fitness, health       0.71      0.72      0.71      6133\n",
      "Government,judiciary       0.76      0.71      0.73      5541\n",
      " Humanities,feelings       0.62      0.66      0.64      5043\n",
      "       Relationships       0.70      0.72      0.71      6613\n",
      "      economy,nation       0.77      0.74      0.75      4853\n",
      "           education       0.76      0.73      0.74      6296\n",
      "       entertainment       0.75      0.82      0.78      7801\n",
      "          human life       0.65      0.58      0.61      5029\n",
      "       life,feelings       0.71      0.67      0.69      5558\n",
      "          technology       0.77      0.80      0.79      7133\n",
      "\n",
      "            accuracy                           0.72     60000\n",
      "           macro avg       0.72      0.71      0.72     60000\n",
      "        weighted avg       0.72      0.72      0.72     60000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7221666666666666\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
